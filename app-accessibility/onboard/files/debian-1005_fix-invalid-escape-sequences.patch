Description: Use double-backslashes instead of single-backslashes in Python code for normal strings.
Author: Mike Gabriel <mike.gabriel@das-netzwerkteam.de>
Forwarded: pending, upstream maintainer is MIA

--- a/Onboard/utils.py
+++ b/Onboard/utils.py
@@ -169,7 +169,7 @@
     [('TAB', 5)]
 
     # regex
-    >>> parse_key_combination(["F\d+"], ["TAB", "F1", "F2", "F3", "F9"])
+    >>> parse_key_combination([r"F\\d+"], ["TAB", "F1", "F2", "F3", "F9"])
     [('F1', 0), ('F2', 0), ('F3', 0), ('F9', 0)]
     """
     modifiers = combo[:-1]
@@ -217,8 +217,8 @@
 def toprettyxml(domdoc):
     ugly_xml = domdoc.toprettyxml(indent='  ')
     # Join lines with text elements with their tag lines
-    pattern = re.compile('>\n\s+([^<>\s].*?)\n\s+</', re.DOTALL)
-    pretty_xml = pattern.sub('>\g<1></', ugly_xml)
+    pattern = re.compile(r'>\n\s+([^<>\s].*?)\n\s+</', re.DOTALL)
+    pretty_xml = pattern.sub(r'>\g<1></', ugly_xml)
 
     # Work around http://bugs.python.org/issue5752
     pretty_xml = re.sub(
@@ -356,8 +356,8 @@
     """
     Converts a list of strings into a dict of tuples.
     Sample list: ['LWIN:label:super', ...]
-    ":" in a value must be escaped as "\:"
-    "\" in a value must be escaped as "\\"
+    ":" in a value must be escaped as "\\:"
+    "\\" in a value must be escaped as "\\\\"
     """
     result = {}
 
@@ -379,8 +379,8 @@
         if tuples:
             a = []
             for t in tuples[0]:
-                t = t.replace("\\\\", "\\")   # unescape backslash
-                t = t.replace("\\:", ":")     # unescape separator
+                t = t.replace(r'\\\\', r'\\')     # unescape backslash
+                t = t.replace(r'\\:', r'\:')      # unescape separator
                 a.append(t)
 
             if key_type == str:
@@ -404,8 +404,8 @@
         text = str(t[0])
         sep = name_sep
         for value in t[1]:
-            value = value.replace("\\", "\\\\")   # escape backslash
-            value = value.replace(sep, "\\"+sep)  # escape separator
+            value = value.replace(r'\\', r'\\\\')   # escape backslash
+            value = value.replace(sep, r'\\'+sep)  # escape separator
             text += sep + '%s' % value
             sep = field_sep
         result.append(text)
@@ -1539,9 +1539,9 @@
 
 
 _tag_pattern = re.compile(
-    """(?:
+    r"""(?:
             <[\w\-_]+                         # tag
-            (?:\s+[\w\-_]+=["'][^"']*["'])*  # attributes
+            (?:\s+[\w\-_]+=["'][^"']*["'])*   # attributes
             /?>
         ) |
         (?:
@@ -1573,7 +1573,7 @@
     [('<tag/>', True), (' ', False), ('<tag2 attr="value"/>', True)]
 
     # must not modify input, i.e. concatenated result must equal input text
-    >>> markup = "asd <tt>t est\\n ds</tt> te st2 "
+    >>> markup = r"asd <tt>t est\n ds</tt> te st2 "
     >>> "".join([text for text, tag in _iter_markup(markup)]) == markup
     True
     """
--- a/Onboard/pypredict/lm_wrapper.py
+++ b/Onboard/pypredict/lm_wrapper.py
@@ -299,13 +299,13 @@
 
 
 SENTENCE_PATTERN = re.compile( \
-    """ .*?
+    r""" .*?
            (?:
-                 (?:[.;:!?](?:(?=[\s]) | \")) # punctuation
-               | (?:\\s*\\n\\s*)+(?=[\\n])    # multiples newlines
-               | <s>                          # sentence end mark
+                 (?:[.;:!?](?:(?=[\s]) | \"))  # punctuation
+               | (?:\s*\n\s*)+(?=[\n])         # multiples newlines
+               | <s>                           # sentence end mark
            )
-         | .+$                                # last sentence fragment
+         | .+$                                 # last sentence fragment
     """, re.UNICODE|re.DOTALL|re.VERBOSE)
 
 def split_sentences(text, disambiguate=False):
@@ -324,7 +324,7 @@
     for match in matches:
         sentence = match.group()
         # not only newlines? remove fragments with only double newlines
-        if True: #not re.match("^\s*\n+\s*$", sentence, re.UNICODE):
+        if True: #not re.match(r"^\s*\n+\s*$", sentence, re.UNICODE):
             begin = match.start()
             end   = match.end()
 
@@ -341,7 +341,7 @@
             sentence = re.sub("<s>", "   ", sentence)
 
             # remove newlines and double spaces - no, invalidates spans
-            #sentence = re.sub(u"\s+", u" ", sentence)
+            #sentence = re.sub(r"\s+", u" ", sentence)
 
             # strip whitespace from the cuts, remove carriage returns
             l = len(sentence)
@@ -365,10 +365,10 @@
     return sentences, spans
 
 
-tokenize_pattern = """
+tokenize_pattern = r"""
     (                                     # <unk>
       (?:^|(?<=\s))
-        \S*(\S)\\2{{3,}}\S*               # char repeated more than 3 times
+        \S*(\S)\2{{3,}}\S*                # char repeated more than 3 times
         | [-]{{3}}                        # dash repeated more than 2 times
       (?=\s|$)
       | :[^\s:@]+?@                       # password in URL
@@ -379,7 +379,7 @@
     ) |
     (                                     # word
       (?:[-]{{0,2}}                       # allow command line options
-        [^\W\d]\w*(?:[-'´΄][\w]+)*        # word, not starting with a digit
+        [^\W\d]\w*(?:[-'´΄[\w]+)*         # word, not starting with a digit
         [{trailing_characters}'´΄]?)
       | <unk> | <s> | </s> | <num>        # pass through control words
       | <bot:[a-z]*>                      # pass through begin of text merkers
@@ -464,11 +464,11 @@
         The result is ready for use in predict().
     """
     tokens, spans = tokenize_text(text, is_context = True)
-    if not re.match("""
-                  ^$                             # empty string?
+    if not re.match(r"""
+                  ^$                              # empty string?
                 | .*[-'´΄\w]$                    # word at the end?
                 | (?:^|.*\s)[|]=?$               # recognized operator?
-                | .*(\S)\\1{3,}$                 # anything repeated > 3 times?
+                | .*(\S)\1{3,}$                 # anything repeated > 3 times?
                 """, text, re.UNICODE|re.DOTALL|re.VERBOSE):
         tokens.append("")
         tend = len(text)
@@ -501,13 +501,13 @@
             continue
 
         if data:  # data section?
-            result = re.search("ngram (\d+)=\d+", line)
+            result = re.search(r"ngram (\d+)=\d+", line)
             if result:
                 if order is None:
                     order = 0
                 order = max(order, int(result.groups()[0]))
 
-            if line.startswith("\\"):  # end of data section?
+            if line.startswith(r"\\"):  # end of data section?
                 break
 
     return order
@@ -621,7 +621,7 @@
             context, spans = tokenize_context(". " + inputline) # simulate sentence begin
             prefix = context[len(context)-1] if context else ""
             prefix_to_end = sentence[len(inputline)-len(prefix):]
-            target_word = re.search("^([\w]|[-'])*", prefix_to_end, re.UNICODE).group()
+            target_word = re.search(r"^([\w]|[-'])*", prefix_to_end, re.UNICODE).group()
             choices = query_model.predict(context, limit)
 
             if 0:  # step mode for debugging
--- a/Onboard/Appearance.py
+++ b/Onboard/Appearance.py
@@ -921,7 +921,7 @@
         ColorScheme._parse_dom_node_item(node, item)
         return item
 
-    _key_ids_pattern = re.compile('[\w-]+(?:[.][\w-]+)?', re.UNICODE)
+    _key_ids_pattern = re.compile(r'[\w-]+(?:[.][\w-]+)?', re.UNICODE)
 
     @staticmethod
     def _parse_key_group(node, used_keys):
@@ -1063,7 +1063,7 @@
 
             # read key ids
             text = "".join([n.data for n in group.childNodes])
-            key_ids = [x for x in re.findall('\w+(?:[.][\w-]+)?', text) if x]
+            key_ids = [x for x in re.findall(r'\w+(?:[.][\w-]+)?', text) if x]
 
             # check for duplicate key definitions
             for key_id in key_ids:
--- a/Onboard/TextDomain.py
+++ b/Onboard/TextDomain.py
@@ -141,7 +141,7 @@
 
         # Split at whitespace to catch whole URLs/file names and
         # keep separators.
-        strings = re.split('(\s+)', context)
+        strings = re.split(r'(\s+)', context)
         if strings:
             string = strings[-1]
             if self._url_parser.is_maybe_url(string):
@@ -174,17 +174,17 @@
         >>> with open(fn2, mode="w") as f: n = f.write("")
 
         # simple file in dir with spaces must return as filename
-        >>> strings = re.split('(\s+)', fn1)
+        >>> strings = re.split(r'(\\s+)', fn1)
         >>> "/test onboard" in d._search_valid_file_name(strings)
         True
 
         # file with spaces in dir with spaces must return as filename
-        >>> strings = re.split('(\s+)', fn2)
+        >>> strings = re.split(r'(\\s+)', fn2)
         >>> "/test onboard" in d._search_valid_file_name(strings)
         True
 
         # random string after a valid file must not be confused with a filename
-        >>> strings = re.split('(\s+)', fn2 + " no-file")
+        >>> strings = re.split(r'(\\s+)', fn2 + " no-file")
         >>> d._search_valid_file_name(strings) is None
         True
         """
@@ -288,7 +288,7 @@
     def handle_key_press(self, keycode, mod_mask):
         return True, None  # entering_text, end_of_editing
 
-    _growth_sections_pattern = re.compile("[^\s?#@]+", re.DOTALL)
+    _growth_sections_pattern = re.compile(r"[^\s?#@]+", re.DOTALL)
 
     def _split_growth_sections(self, text):
         """
@@ -442,21 +442,21 @@
 
     _prompt_patterns = tuple(re.compile(p, re.UNICODE) for p in
                                 (
-                                    "^gdb$ ",
-                                    "^>>> ",              # python
-                                    "^In \[[0-9]*\]: ",   # ipython
-                                    "^:",                 # vi command mode
-                                    "^/",                 # vi search
-                                    "^\?",                # vi reverse search
-                                    "\$ ",                # generic prompt
-                                    "# ",                 # root prompt
-                                    "^.*?@.*?/.*?> "      # fish
+                                    r"^gdb$ ",
+                                    r"^>>> ",              # python
+                                    r"^In \[[0-9]*\]: ",   # ipython
+                                    r"^:",                 # vi command mode
+                                    r"^/",                 # vi search
+                                    r"^\?",                # vi reverse search
+                                    r"\$ ",                # generic prompt
+                                    r"# ",                 # root prompt
+                                    r"^.*?@.*?/.*?> "      # fish
                                 )
                             )
 
     _prompt_blacklist_patterns = tuple(re.compile(p, re.UNICODE) for p in
                                 (
-                                    "^\(.*\)`.*': ",  # bash incremental search
+                                    r"^\(.*\)`.*': ",  # bash incremental search
                                 )
                             )
 
@@ -736,7 +736,7 @@
     _protocols = ["mailto", "apt"]
     _all_schemes = _schemes + _protocols
 
-    _url_pattern = re.compile("([\w-]+)|(\W+)", re.UNICODE)
+    _url_pattern = re.compile(r"([\w-]+)|(\W+)", re.UNICODE)
 
     def iter_url(self, url):
         return self._url_pattern.finditer(url)
--- a/setup.py
+++ b/setup.py
@@ -115,7 +115,7 @@
               .format(repr(package), status), file=sys.stderr)
         sys.exit(2)
 
-    version = re.search('(?:(?:\d+)\.)+\d+', output).group()
+    version = re.search(r'(?:(?:\d+)\.)+\d+', output).group()
     components = version.split(".")
     major, minor = int(components[0]), int(components[1])
     revision = int(components[2]) if len(components) >= 3 else 0
--- a/Onboard/LayoutLoaderSVG.py
+++ b/Onboard/LayoutLoaderSVG.py
@@ -95,7 +95,7 @@
         self._layout_filename = ""
         self._color_scheme = None
         self._root_layout_dir = ""  # path to svg files
-        self._layout_regex = re.compile("([^\(]+) (?: \( ([^\)]*) \) )?",
+        self._layout_regex = re.compile(r"([^\(]+) (?: \( ([^\)]*) \) )?",
                                         re.VERBOSE)
 
     def load(self, vk, layout_filename, color_scheme):
--- a/Onboard/SpellChecker.py
+++ b/Onboard/SpellChecker.py
@@ -321,7 +321,7 @@
     def is_running(self):
         return not self._osk_hunspell is None
 
-    SPLITWORDS = re.compile("[^-_\s]+", re.UNICODE|re.DOTALL)
+    SPLITWORDS = re.compile(r"[^-_\s]+", re.UNICODE|re.DOTALL)
 
     def query(self, text):
         """
--- a/Onboard/WordSuggestions.py
+++ b/Onboard/WordSuggestions.py
@@ -1250,8 +1250,8 @@
                 return word_span
         return None
 
-    _section_begin_pattern = re.compile("\S*\s*$")
-    _section_end_pattern = re.compile("\S*(?=\s*)")
+    _section_begin_pattern = re.compile(r"\S*\s*$")
+    _section_end_pattern = re.compile(r"\S*(?=\s*)")
 
     def _get_section_before_span(self, insertion_span):
         """
--- a/Onboard/test/test_gui.py
+++ b/Onboard/test/test_gui.py
@@ -894,8 +894,8 @@
                 tw = self.TextWindow()
                 with self._run_onboard() as instance:
                     groups = [m.groups() for m
-                              in re.finditer("(?: \[ ([^\]]*) ) |"
-                                             "(?: \] ([^\[]*) )",
+                              in re.finditer(r"(?: \[ ([^\]]*) ) |"
+                                             r"(?: \] ([^\[]*) )",
                                              challenge, re.VERBOSE)]
                     for key_id, text in groups:
                         if key_id:
